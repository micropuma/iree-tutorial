// -----// IR Dump After TosaToMLProgram (tosa-to-mlprogram) //----- //
module {
  func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
    %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
    return %0 : tensor<12x6xf32>
  }
}


// -----// IR Dump After TosaToSCF (tosa-to-scf) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
  return %0 : tensor<12x6xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
  return %0 : tensor<12x6xf32>
}

// -----// IR Dump After Inliner (inline) //----- //
module {
  func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
    %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
    return %0 : tensor<12x6xf32>
  }
}


// -----// IR Dump After TosaMakeBroadcastable (tosa-make-broadcastable) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
  return %0 : tensor<12x6xf32>
}

// -----// IR Dump After TosaToArith (tosa-to-arith) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
  return %0 : tensor<12x6xf32>
}

// -----// IR Dump After TosaToTensor (tosa-to-tensor) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
  return %0 : tensor<12x6xf32>
}

// -----// IR Dump After TosaToLinalgExtPass (iree-tosa-to-linalg-ext) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
  return %0 : tensor<12x6xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
  return %0 : tensor<12x6xf32>
}

// -----// IR Dump After TosaOptionalDecompositions (tosa-optional-decompositions) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
  return %0 : tensor<12x6xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
  return %0 : tensor<12x6xf32>
}

// -----// IR Dump After TosaInferShapes (tosa-infer-shapes) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
  return %0 : tensor<12x6xf32>
}

// -----// IR Dump After TosaMakeBroadcastable (tosa-make-broadcastable) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
  return %0 : tensor<12x6xf32>
}

// -----// IR Dump After TosaToLinalgNamed (tosa-to-linalg-named) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
  return %0 : tensor<12x6xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
  return %0 : tensor<12x6xf32>
}

// -----// IR Dump After TosaLayerwiseConstantFoldPass (tosa-layerwise-constant-fold) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
  return %0 : tensor<12x6xf32>
}

// -----// IR Dump After TosaMakeBroadcastable (tosa-make-broadcastable) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
  return %0 : tensor<12x6xf32>
}

// -----// IR Dump After TosaValidation (tosa-validate) //----- //
module {
  func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
    %0 = tosa.add %arg0, %arg1 : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
    return %0 : tensor<12x6xf32>
  }
}


// -----// IR Dump After TosaToLinalg (tosa-to-linalg) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tensor.empty() : tensor<12x6xf32>
  %1 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%0 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %2 = arith.addf %in, %in_0 : f32
    linalg.yield %2 : f32
  } -> tensor<12x6xf32>
  return %1 : tensor<12x6xf32>
}

// -----// IR Dump After Converti48Toi64Pass (iree-tosa-convert-i48-to-i64) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tensor.empty() : tensor<12x6xf32>
  %1 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%0 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %2 = arith.addf %in, %in_0 : f32
    linalg.yield %2 : f32
  } -> tensor<12x6xf32>
  return %1 : tensor<12x6xf32>
}

// -----// IR Dump After TosaToArith (tosa-to-arith) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tensor.empty() : tensor<12x6xf32>
  %1 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%0 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %2 = arith.addf %in, %in_0 : f32
    linalg.yield %2 : f32
  } -> tensor<12x6xf32>
  return %1 : tensor<12x6xf32>
}

// -----// IR Dump After TosaToTensor (tosa-to-tensor) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tensor.empty() : tensor<12x6xf32>
  %1 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%0 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %2 = arith.addf %in, %in_0 : f32
    linalg.yield %2 : f32
  } -> tensor<12x6xf32>
  return %1 : tensor<12x6xf32>
}

// -----// IR Dump After StripSignednessPass (iree-tosa-strip-signedness) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tensor.empty() : tensor<12x6xf32>
  %1 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%0 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %2 = arith.addf %in, %in_0 : f32
    linalg.yield %2 : f32
  } -> tensor<12x6xf32>
  return %1 : tensor<12x6xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tensor.empty() : tensor<12x6xf32>
  %1 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%0 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %2 = arith.addf %in, %in_0 : f32
    linalg.yield %2 : f32
  } -> tensor<12x6xf32>
  return %1 : tensor<12x6xf32>
}

// -----// IR Dump After VerifyCompilerTOSAInputLegalityPass (iree-tosa-verify-compiler-input-legality) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
    %0 = tensor.empty() : tensor<12x6xf32>
    %1 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%0 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.addf %in, %in_0 : f32
      linalg.yield %2 : f32
    } -> tensor<12x6xf32>
    return %1 : tensor<12x6xf32>
  }
}


// -----// IR Dump After AutoInputConversionPipelinePass (iree-auto-input-conversion) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  func.func @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
    %0 = tensor.empty() : tensor<12x6xf32>
    %1 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%0 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.addf %in, %in_0 : f32
      linalg.yield %2 : f32
    } -> tensor<12x6xf32>
    return %1 : tensor<12x6xf32>
  }
}


// -----// IR Dump After IREEImportPublicPass (iree-import-public) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
    %0 = tensor.empty() : tensor<12x6xf32>
    %1 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%0 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.addf %in, %in_0 : f32
      linalg.yield %2 : f32
    } -> tensor<12x6xf32>
    util.return %1 : tensor<12x6xf32>
  }
}


// -----// IR Dump After ImportMLProgramPass (iree-import-ml-program) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
    %0 = tensor.empty() : tensor<12x6xf32>
    %1 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%0 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.addf %in, %in_0 : f32
      linalg.yield %2 : f32
    } -> tensor<12x6xf32>
    util.return %1 : tensor<12x6xf32>
  }
}


// -----// IR Dump After SanitizeModuleNamesPass (iree-sanitize-module-names) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
    %0 = tensor.empty() : tensor<12x6xf32>
    %1 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%0 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.addf %in, %in_0 : f32
      linalg.yield %2 : f32
    } -> tensor<12x6xf32>
    util.return %1 : tensor<12x6xf32>
  }
}


// -----// IR Dump After ConvertMeshToFlowPass (iree-convert-mesh-to-flow) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
    %0 = tensor.empty() : tensor<12x6xf32>
    %1 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%0 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.addf %in, %in_0 : f32
      linalg.yield %2 : f32
    } -> tensor<12x6xf32>
    util.return %1 : tensor<12x6xf32>
  }
}


// -----// IR Dump After DemoteF64ToF32Pass (iree-input-conversion-demote-f64-to-f32) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
    %0 = tensor.empty() : tensor<12x6xf32>
    %1 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%0 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.addf %in, %in_0 : f32
      linalg.yield %2 : f32
    } -> tensor<12x6xf32>
    util.return %1 : tensor<12x6xf32>
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::ABI::ConvertStreamableOpsPass (iree-abi-convert-streamable-ops) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
    %0 = tensor.empty() : tensor<12x6xf32>
    %1 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%0 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.addf %in, %in_0 : f32
      linalg.yield %2 : f32
    } -> tensor<12x6xf32>
    util.return %1 : tensor<12x6xf32>
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::ABI::WrapEntryPointsPass (iree-abi-wrap-entry-points) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = util.call @_add(%0, %1) : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
    %3 = hal.tensor.export %2 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
  util.func private @_add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
    %0 = tensor.empty() : tensor<12x6xf32>
    %1 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%0 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %2 = arith.addf %in, %in_0 : f32
      linalg.yield %2 : f32
    } -> tensor<12x6xf32>
    util.return %1 : tensor<12x6xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func private @_add(%arg0: tensor<12x6xf32>, %arg1: tensor<12x6xf32>) -> tensor<12x6xf32> {
  %0 = tensor.empty() : tensor<12x6xf32>
  %1 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%arg0, %arg1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%0 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %2 = arith.addf %in, %in_0 : f32
    linalg.yield %2 : f32
  } -> tensor<12x6xf32>
  util.return %1 : tensor<12x6xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = util.call @_add(%0, %1) : (tensor<12x6xf32>, tensor<12x6xf32>) -> tensor<12x6xf32>
  %3 = hal.tensor.export %2 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After Inliner (inline) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeTargetDevicesPass (iree-hal-materialize-target-devices) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveDevicePromisesPass (iree-hal-resolve-device-promises) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveDeviceAliasesPass (iree-hal-resolve-device-aliases) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyDevicesPass (iree-hal-verify-devices) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After LinalgQuantizedConvToConvPass (iree-global-opt-quantized-conv-to-conv) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After LinalgQuantizedMatmulToMatmulPass (iree-global-opt-quantized-matmul-to-matmul) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After RemoveZeroExtentTensorsPass (iree-global-opt-remove-zero-extent-tensors) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After DetachElementwiseFromNamedOpsPass (iree-global-opt-detach-elementwise-from-named-ops) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After LinalgNamedOpConversionPass (linalg-named-op-conversion) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After EraseUnusedLinalgOperandsPass (iree-global-opt-erase-unused-linalg-operands) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ExpandTensorShapesPass (iree-global-opt-expand-tensor-shapes) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ConvertElementwiseToLinalgPass (convert-elementwise-to-linalg) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After RaiseSpecialOpsPass (iree-global-opt-raise-special-ops) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After DecomposeConcatPass (iree-global-opt-decompose-concat) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After GeneralizeLinalgNamedOpsPass (iree-global-opt-generalize-linalg-named-ops) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After FoldUnitExtentDimsPass (iree-dispatch-creation-fold-unit-extent-dims) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After DemoteContractionInputsToBF16Pass (iree-global-opt-demote-contraction-inputs-to-bf16) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After SetEncodingPass (iree-dispatch-creation-set-encoding) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After MaterializeEncodingIntoNopPass (iree-codegen-materialize-encoding-into-nop) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After MaterializeHomogeneousEncodingsPass (iree-global-opt-materialize-homogeneous-encodings) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyPackUnpackPass (iree-global-opt-simplify-pack-unpack) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After DataLayoutPropagationPass (iree-global-opt-data-layout-propagation) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After GeneralizeLinalgNamedOpsPass (iree-global-opt-generalize-linalg-named-ops) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After GlobalLoopInvariantCodeMotionPass (iree-global-opt-loop-invariant-code-motion) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After HoistIntoGlobals (iree-util-hoist-into-globals) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After JitGlobalsPass (iree-consteval-jit-globals) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After RaiseSpecialOpsPass (iree-global-opt-raise-special-ops) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After InjectTensorTracingPass (iree-flow-inject-tensor-tracing) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After TensorPadToTensorInsertSlicePass (iree-dispatch-creation-tensor-pad-to-tensor-insert-slice) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#map = affine_map<(d0, d1) -> (d0, d1)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = tensor.empty() : tensor<12x6xf32>
    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<12x6xf32>
    %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FusionPreprocessingPass (iree-dispatch-creation-fusion-preprocessing) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After ElementwiseOpFusionPass (iree-dispatch-creation-elementwise-op-fusion) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After BubbleUpExpandShapesPass (iree-dispatch-creation-bubble-up-expand-shapes) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After BubbleUpExtractSlicesPass (iree-dispatch-creation-bubble-up-extract-slices) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After ElementwiseOpFusionPass (iree-dispatch-creation-elementwise-op-fusion) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After SinkReshapesPass (iree-dispatch-creation-sink-reshapes) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After FuseMultiUseElementwiseProducerPass (iree-dispatch-creation-fuse-multi-use-elementwise-producer) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After SplitReductionPass (iree-dispatch-creation-split-reduction-ops) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After TransposeGenericOpsPass (iree-dispatch-creation-transpose-generic-ops) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After FormScalarDispatchesPass (iree-dispatch-creation-form-scalar-dispatches) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<12x6xf32>
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After FormDispatchRegionsPass (iree-dispatch-creation-form-dispatch-regions) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = tensor.empty() : tensor<12x6xf32>
  %3 = flow.dispatch.region -> (tensor<12x6xf32>) {
    %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%2 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %6 = arith.addf %in, %in_0 : f32
      linalg.yield %6 : f32
    } -> tensor<12x6xf32>
    flow.return %5 : tensor<12x6xf32>
  }
  %4 = hal.tensor.export %3 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CloneProducersIntoDispatchRegionsPass (iree-dispatch-creation-clone-producers-into-dispatch-regions) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.dispatch.region -> (tensor<12x6xf32>) {
    %4 = tensor.empty() : tensor<12x6xf32>
    %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%0, %1 : tensor<12x6xf32>, tensor<12x6xf32>) outs(%4 : tensor<12x6xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %6 = arith.addf %in, %in_0 : f32
      linalg.yield %6 : f32
    } -> tensor<12x6xf32>
    flow.return %5 : tensor<12x6xf32>
  }
  %3 = hal.tensor.export %2 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After CollapseDimensionsPass (iree-dispatch-creation-collapse-dimensions) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %collapsed = tensor.collapse_shape %0 [[0, 1]] : tensor<12x6xf32> into tensor<72xf32>
  %collapsed_0 = tensor.collapse_shape %1 [[0, 1]] : tensor<12x6xf32> into tensor<72xf32>
  %2 = flow.dispatch.region -> (tensor<72xf32>) {
    %4 = tensor.empty() : tensor<72xf32>
    %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %collapsed_0 : tensor<72xf32>, tensor<72xf32>) outs(%4 : tensor<72xf32>) {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %6 = arith.addf %in, %in_2 : f32
      linalg.yield %6 : f32
    } -> tensor<72xf32>
    %expanded_1 = tensor.expand_shape %5 [[0, 1]] output_shape [12, 6] : tensor<72xf32> into tensor<12x6xf32>
    flow.return %5 : tensor<72xf32>
  }
  %expanded = tensor.expand_shape %2 [[0, 1]] output_shape [12, 6] : tensor<72xf32> into tensor<12x6xf32>
  %3 = hal.tensor.export %expanded "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After ConvertDispatchRegionsToWorkgroupsPass (iree-dispatch-creation-convert-dispatch-regions-to-workgroups) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %collapsed = tensor.collapse_shape %0 [[0, 1]] : tensor<12x6xf32> into tensor<72xf32>
  %collapsed_0 = tensor.collapse_shape %1 [[0, 1]] : tensor<12x6xf32> into tensor<72xf32>
  %2 = flow.dispatch.workgroups(%collapsed, %collapsed_0) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32> =
      (%arg2: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg4: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
    %4 = flow.dispatch.tensor.load %arg2, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %5 = flow.dispatch.tensor.load %arg3, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %6 = tensor.empty() : tensor<72xf32>
    %7 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%4, %5 : tensor<72xf32>, tensor<72xf32>) outs(%6 : tensor<72xf32>) {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %8 = arith.addf %in, %in_2 : f32
      linalg.yield %8 : f32
    } -> tensor<72xf32>
    %expanded_1 = tensor.expand_shape %7 [[0, 1]] output_shape [12, 6] : tensor<72xf32> into tensor<12x6xf32>
    flow.dispatch.tensor.store %7, %arg4, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
    flow.return
  }
  %expanded = tensor.expand_shape %2 [[0, 1]] output_shape [12, 6] : tensor<72xf32> into tensor<12x6xf32>
  %3 = hal.tensor.export %expanded "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After ConvertTensorToFlowPass (iree-dispatch-creation-convert-tensor-to-flow) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch.workgroups(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32> =
      (%arg2: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg4: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
    %7 = flow.dispatch.tensor.load %arg2, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %8 = flow.dispatch.tensor.load %arg3, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %9 = tensor.empty() : tensor<72xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%7, %8 : tensor<72xf32>, tensor<72xf32>) outs(%9 : tensor<72xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %11 = arith.addf %in, %in_0 : f32
      linalg.yield %11 : f32
    } -> tensor<72xf32>
    flow.dispatch.tensor.store %10, %arg4, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
    flow.return
  }
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch.workgroups(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32> =
      (%arg2: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg4: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
    %7 = flow.dispatch.tensor.load %arg2, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %8 = flow.dispatch.tensor.load %arg3, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %9 = tensor.empty() : tensor<72xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%7, %8 : tensor<72xf32>, tensor<72xf32>) outs(%9 : tensor<72xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %11 = arith.addf %in, %in_0 : f32
      linalg.yield %11 : f32
    } -> tensor<72xf32>
    flow.dispatch.tensor.store %10, %arg4, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
    flow.return
  }
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch.workgroups(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32> =
      (%arg2: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg4: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
    %7 = flow.dispatch.tensor.load %arg2, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %8 = flow.dispatch.tensor.load %arg3, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %9 = tensor.empty() : tensor<72xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%7, %8 : tensor<72xf32>, tensor<72xf32>) outs(%9 : tensor<72xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %11 = arith.addf %in, %in_0 : f32
      linalg.yield %11 : f32
    } -> tensor<72xf32>
    flow.dispatch.tensor.store %10, %arg4, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
    flow.return
  }
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After MaterializeDefaultWorkgroupCountRegionPass (iree-dispatch-creation-materialize-default-workgroup-count-region) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch.workgroups(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32> =
      (%arg2: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg4: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
    %7 = flow.dispatch.tensor.load %arg2, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %8 = flow.dispatch.tensor.load %arg3, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %9 = tensor.empty() : tensor<72xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%7, %8 : tensor<72xf32>, tensor<72xf32>) outs(%9 : tensor<72xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %11 = arith.addf %in, %in_0 : f32
      linalg.yield %11 : f32
    } -> tensor<72xf32>
    flow.dispatch.tensor.store %10, %arg4, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    flow.return %x, %y, %z : index, index, index
  }
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After VerifyInputLegalityPass (iree-verify-input-legality) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
    %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
    %4 = flow.dispatch.workgroups(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32> =
        (%arg2: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg4: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
      %7 = flow.dispatch.tensor.load %arg2, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
      %8 = flow.dispatch.tensor.load %arg3, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
      %9 = tensor.empty() : tensor<72xf32>
      %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%7, %8 : tensor<72xf32>, tensor<72xf32>) outs(%9 : tensor<72xf32>) {
      ^bb0(%in: f32, %in_0: f32, %out: f32):
        %11 = arith.addf %in, %in_0 : f32
        linalg.yield %11 : f32
      } -> tensor<72xf32>
      flow.dispatch.tensor.store %10, %arg4, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After CaptureDynamicDimsPass (iree-flow-capture-dynamic-dims) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch.workgroups(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32> =
      (%arg2: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg4: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
    %7 = flow.dispatch.tensor.load %arg2, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %8 = flow.dispatch.tensor.load %arg3, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %9 = tensor.empty() : tensor<72xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%7, %8 : tensor<72xf32>, tensor<72xf32>) outs(%9 : tensor<72xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %11 = arith.addf %in, %in_0 : f32
      linalg.yield %11 : f32
    } -> tensor<72xf32>
    flow.dispatch.tensor.store %10, %arg4, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    flow.return %x, %y, %z : index, index, index
  }
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch.workgroups(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32> =
      (%arg2: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg4: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
    %7 = flow.dispatch.tensor.load %arg2, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %8 = flow.dispatch.tensor.load %arg3, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %9 = tensor.empty() : tensor<72xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%7, %8 : tensor<72xf32>, tensor<72xf32>) outs(%9 : tensor<72xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %11 = arith.addf %in, %in_0 : f32
      linalg.yield %11 : f32
    } -> tensor<72xf32>
    flow.dispatch.tensor.store %10, %arg4, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    flow.return %x, %y, %z : index, index, index
  }
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch.workgroups(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32> =
      (%arg2: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg4: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
    %7 = flow.dispatch.tensor.load %arg2, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %8 = flow.dispatch.tensor.load %arg3, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %9 = tensor.empty() : tensor<72xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%7, %8 : tensor<72xf32>, tensor<72xf32>) outs(%9 : tensor<72xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %11 = arith.addf %in, %in_0 : f32
      linalg.yield %11 : f32
    } -> tensor<72xf32>
    flow.dispatch.tensor.store %10, %arg4, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    flow.return %x, %y, %z : index, index, index
  }
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After InitializeEmptyTensorsPass (iree-flow-initialize-empty-tensors) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch.workgroups(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32> =
      (%arg2: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg4: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
    %7 = flow.dispatch.tensor.load %arg2, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %8 = flow.dispatch.tensor.load %arg3, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
    %9 = tensor.empty() : tensor<72xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%7, %8 : tensor<72xf32>, tensor<72xf32>) outs(%9 : tensor<72xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %11 = arith.addf %in, %in_0 : f32
      linalg.yield %11 : f32
    } -> tensor<72xf32>
    flow.dispatch.tensor.store %10, %arg4, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    flow.return %x, %y, %z : index, index, index
  }
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After OutlineDispatchExternsPass (iree-flow-outline-dispatch-externs) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
    %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
    %4 = flow.dispatch.workgroups(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32> =
        (%arg2: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg4: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
      %7 = flow.dispatch.tensor.load %arg2, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
      %8 = flow.dispatch.tensor.load %arg3, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
      %9 = tensor.empty() : tensor<72xf32>
      %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%7, %8 : tensor<72xf32>, tensor<72xf32>) outs(%9 : tensor<72xf32>) {
      ^bb0(%in: f32, %in_0: f32, %out: f32):
        %11 = arith.addf %in, %in_0 : f32
        linalg.yield %11 : f32
      } -> tensor<72xf32>
      flow.dispatch.tensor.store %10, %arg4, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
      flow.return
    } count() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After OutlineDispatchRegionsPass (iree-flow-outline-dispatch-regions) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  flow.executable private @add_dispatch_0 {
    flow.executable.export public @add_dispatch_0 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg2: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %2 = tensor.empty() : tensor<72xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%0, %1 : tensor<72xf32>, tensor<72xf32>) outs(%2 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %4 = arith.addf %in, %in_0 : f32
          linalg.yield %4 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
    %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
    %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
    %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateDispatchesPass (iree-flow-annotate-dispatches) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  flow.executable private @add_dispatch_0 {
    flow.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg2: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %2 = tensor.empty() : tensor<72xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%0, %1 : tensor<72xf32>, tensor<72xf32>) outs(%2 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %4 = arith.addf %in, %in_0 : f32
          linalg.yield %4 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
    %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
    %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
    %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After StripDebugOps (iree-util-strip-debug-ops) //----- //
flow.executable private @add_dispatch_0 {
  flow.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    flow.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @add_dispatch_0_elementwise_72_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg2: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
      %0 = flow.dispatch.tensor.load %arg0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
      %1 = flow.dispatch.tensor.load %arg1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
      %2 = tensor.empty() : tensor<72xf32>
      %3 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%0, %1 : tensor<72xf32>, tensor<72xf32>) outs(%2 : tensor<72xf32>) {
      ^bb0(%in: f32, %in_0: f32, %out: f32):
        %4 = arith.addf %in, %in_0 : f32
        linalg.yield %4 : f32
      } -> tensor<72xf32>
      flow.dispatch.tensor.store %3, %arg2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
      return
    }
  }
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After DeduplicateExecutablesPass (iree-flow-deduplicate-executables) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  flow.executable private @add_dispatch_0 {
    flow.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg2: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %2 = tensor.empty() : tensor<72xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%0, %1 : tensor<72xf32>, tensor<72xf32>) outs(%2 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %4 = arith.addf %in, %in_0 : f32
          linalg.yield %4 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
    %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
    %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
    %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After InjectTensorTracingPass (iree-flow-inject-tensor-tracing) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CleanupTensorShapesPass (iree-flow-cleanup-tensor-shapes) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After OutlineConstantsPass (iree-flow-outline-constants) //----- //
#map = affine_map<(d0) -> (d0)>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  flow.executable private @add_dispatch_0 {
    flow.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg2: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %2 = tensor.empty() : tensor<72xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%0, %1 : tensor<72xf32>, tensor<72xf32>) outs(%2 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %4 = arith.addf %in, %in_0 : f32
          linalg.yield %4 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
    %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
    %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
    %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CanonicalizerPass (iree-flow-canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  flow.executable private @add_dispatch_0 {
    flow.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg2: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %2 = tensor.empty() : tensor<72xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%0, %1 : tensor<72xf32>, tensor<72xf32>) outs(%2 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %4 = arith.addf %in, %in_0 : f32
          linalg.yield %4 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
    %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
    %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
    %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  flow.executable private @add_dispatch_0 {
    flow.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg2: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %2 = tensor.empty() : tensor<72xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%0, %1 : tensor<72xf32>, tensor<72xf32>) outs(%2 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %4 = arith.addf %in, %in_0 : f32
          linalg.yield %4 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
    %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
    %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
    %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#map = affine_map<(d0) -> (d0)>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  flow.executable private @add_dispatch_0 {
    flow.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg2: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %2 = tensor.empty() : tensor<72xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%0, %1 : tensor<72xf32>, tensor<72xf32>) outs(%2 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %4 = arith.addf %in, %in_0 : f32
          linalg.yield %4 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
    %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
    %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
    %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  flow.executable private @add_dispatch_0 {
    flow.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg2: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %2 = tensor.empty() : tensor<72xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%0, %1 : tensor<72xf32>, tensor<72xf32>) outs(%2 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %4 = arith.addf %in, %in_0 : f32
          linalg.yield %4 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
    %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
    %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
    %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  flow.executable private @add_dispatch_0 {
    flow.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg2: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %2 = tensor.empty() : tensor<72xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%0, %1 : tensor<72xf32>, tensor<72xf32>) outs(%2 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %4 = arith.addf %in, %in_0 : f32
          linalg.yield %4 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
    %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
    %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
    %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyInputPass (iree-stream-verify-input) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  flow.executable private @add_dispatch_0 {
    flow.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg2: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %2 = tensor.empty() : tensor<72xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%0, %1 : tensor<72xf32>, tensor<72xf32>) outs(%2 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %4 = arith.addf %in, %in_0 : f32
          linalg.yield %4 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
    %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
    %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
    %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
  %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
  %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
  %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
  %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
  %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
  %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  flow.executable private @add_dispatch_0 {
    flow.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg2: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %2 = tensor.empty() : tensor<72xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%0, %1 : tensor<72xf32>, tensor<72xf32>) outs(%2 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %4 = arith.addf %in, %in_0 : f32
          linalg.yield %4 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
    %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
    %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
    %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  flow.executable private @add_dispatch_0 {
    flow.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg2: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %2 = tensor.empty() : tensor<72xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%0, %1 : tensor<72xf32>, tensor<72xf32>) outs(%2 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %4 = arith.addf %in, %in_0 : f32
          linalg.yield %4 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
    %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
    %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
    %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  flow.executable private @add_dispatch_0 {
    flow.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<72xf32>>, %arg2: !flow.dispatch.tensor<writeonly:tensor<72xf32>>) {
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %2 = tensor.empty() : tensor<72xf32>
        %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%0, %1 : tensor<72xf32>, tensor<72xf32>) outs(%2 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %4 = arith.addf %in, %in_0 : f32
          linalg.yield %4 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %3, %arg2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %0 = hal.tensor.import %arg0 "input0" : !hal.buffer_view -> tensor<12x6xf32>
    %1 = hal.tensor.import %arg1 "input1" : !hal.buffer_view -> tensor<12x6xf32>
    %2 = flow.tensor.reshape %0 : tensor<12x6xf32> -> tensor<72xf32>
    %3 = flow.tensor.reshape %1 : tensor<12x6xf32> -> tensor<72xf32>
    %4 = flow.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2, %3) : (tensor<72xf32>, tensor<72xf32>) -> tensor<72xf32>
    %5 = flow.tensor.reshape %4 : tensor<72xf32> -> tensor<12x6xf32>
    %6 = hal.tensor.export %5 "output0" : tensor<12x6xf32> -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After ConvertToStreamPass (iree-stream-conversion) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    %c12 = arith.constant 12 : index
    %c6 = arith.constant 6 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof tensor<12x6xf32> : index
    %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %element_type_f32_0 = hal.element_type<f32> : i32
    %dense_row_major_1 = hal.encoding_type<dense_row_major> : i32
    %c12_2 = arith.constant 12 : index
    %c6_3 = arith.constant 6 : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12_2, %c6_3]) type(%element_type_f32_0) encoding(%dense_row_major_1)
    %3 = stream.tensor.sizeof tensor<12x6xf32> : index
    %4 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    %6 = stream.tensor.sizeof tensor<72xf32> : index
    %7 = stream.tensor.clone %2 : tensor<12x6xf32> in !stream.resource<*>{%0} -> tensor<72xf32> in !stream.resource<*>{%6}
    %8 = stream.tensor.sizeof tensor<72xf32> : index
    %9 = stream.tensor.clone %5 : tensor<12x6xf32> in !stream.resource<*>{%3} -> tensor<72xf32> in !stream.resource<*>{%8}
    %c0 = arith.constant 0 : index
    %10 = stream.tensor.sizeof tensor<72xf32> : index
    %11 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%7[%c0 to %6 for %6], %9[%c0 to %8 for %8]) : (!stream.resource<*>{%6}, !stream.resource<*>{%8}) -> !stream.resource<*>{%10}
    %12 = stream.tensor.sizeof tensor<12x6xf32> : index
    %13 = stream.tensor.clone %11 : tensor<72xf32> in !stream.resource<*>{%10} -> tensor<12x6xf32> in !stream.resource<*>{%12}
    %14 = stream.async.transfer %13 : !stream.resource<*>{%12} -> !stream.resource<external>{%12}
    %15 = stream.tensor.export %14 : tensor<12x6xf32> in !stream.resource<external>{%12} -> !hal.buffer_view
    util.return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToTensorsPass (iree-stream-verify-lowering-to-tensors) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    %c12 = arith.constant 12 : index
    %c6 = arith.constant 6 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof tensor<12x6xf32> : index
    %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %element_type_f32_0 = hal.element_type<f32> : i32
    %dense_row_major_1 = hal.encoding_type<dense_row_major> : i32
    %c12_2 = arith.constant 12 : index
    %c6_3 = arith.constant 6 : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12_2, %c6_3]) type(%element_type_f32_0) encoding(%dense_row_major_1)
    %3 = stream.tensor.sizeof tensor<12x6xf32> : index
    %4 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    %6 = stream.tensor.sizeof tensor<72xf32> : index
    %7 = stream.tensor.clone %2 : tensor<12x6xf32> in !stream.resource<*>{%0} -> tensor<72xf32> in !stream.resource<*>{%6}
    %8 = stream.tensor.sizeof tensor<72xf32> : index
    %9 = stream.tensor.clone %5 : tensor<12x6xf32> in !stream.resource<*>{%3} -> tensor<72xf32> in !stream.resource<*>{%8}
    %c0 = arith.constant 0 : index
    %10 = stream.tensor.sizeof tensor<72xf32> : index
    %11 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%7[%c0 to %6 for %6], %9[%c0 to %8 for %8]) : (!stream.resource<*>{%6}, !stream.resource<*>{%8}) -> !stream.resource<*>{%10}
    %12 = stream.tensor.sizeof tensor<12x6xf32> : index
    %13 = stream.tensor.clone %11 : tensor<72xf32> in !stream.resource<*>{%10} -> tensor<12x6xf32> in !stream.resource<*>{%12}
    %14 = stream.async.transfer %13 : !stream.resource<*>{%12} -> !stream.resource<external>{%12}
    %15 = stream.tensor.export %14 : tensor<12x6xf32> in !stream.resource<external>{%12} -> !hal.buffer_view
    util.return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
  %c0 = arith.constant 0 : index
  %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
  %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
  %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
  %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
  %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
  %5 = tensor.empty() : tensor<72xf32>
  %6 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<72xf32>
  flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof tensor<12x6xf32> : index
  %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
  %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %element_type_f32_0 = hal.element_type<f32> : i32
  %dense_row_major_1 = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32_0) encoding(%dense_row_major_1)
  %3 = stream.tensor.sizeof tensor<12x6xf32> : index
  %4 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %6 = stream.tensor.sizeof tensor<72xf32> : index
  %7 = stream.tensor.sizeof tensor<72xf32> : index
  %8 = stream.tensor.sizeof tensor<72xf32> : index
  %9 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2[%c0 to %6 for %6], %5[%c0 to %7 for %7]) : (!stream.resource<*>{%6}, !stream.resource<*>{%7}) -> !stream.resource<*>{%8}
  %10 = stream.tensor.sizeof tensor<12x6xf32> : index
  %11 = stream.async.transfer %9 : !stream.resource<*>{%10} -> !stream.resource<external>{%10}
  %12 = stream.tensor.export %11 : tensor<12x6xf32> in !stream.resource<external>{%10} -> !hal.buffer_view
  util.return %12 : !hal.buffer_view
}

// -----// IR Dump After Inliner (inline) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof tensor<12x6xf32> : index
    %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %element_type_f32_0 = hal.element_type<f32> : i32
    %dense_row_major_1 = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32_0) encoding(%dense_row_major_1)
    %3 = stream.tensor.sizeof tensor<12x6xf32> : index
    %4 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    %6 = stream.tensor.sizeof tensor<72xf32> : index
    %7 = stream.tensor.sizeof tensor<72xf32> : index
    %8 = stream.tensor.sizeof tensor<72xf32> : index
    %9 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2[%c0 to %6 for %6], %5[%c0 to %7 for %7]) : (!stream.resource<*>{%6}, !stream.resource<*>{%7}) -> !stream.resource<*>{%8}
    %10 = stream.tensor.sizeof tensor<12x6xf32> : index
    %11 = stream.async.transfer %9 : !stream.resource<*>{%10} -> !stream.resource<external>{%10}
    %12 = stream.tensor.export %11 : tensor<12x6xf32> in !stream.resource<external>{%10} -> !hal.buffer_view
    util.return %12 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof tensor<12x6xf32> : index
  %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
  %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %element_type_f32_0 = hal.element_type<f32> : i32
  %dense_row_major_1 = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32_0) encoding(%dense_row_major_1)
  %3 = stream.tensor.sizeof tensor<12x6xf32> : index
  %4 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %6 = stream.tensor.sizeof tensor<72xf32> : index
  %7 = stream.tensor.sizeof tensor<72xf32> : index
  %8 = stream.tensor.sizeof tensor<72xf32> : index
  %9 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2[%c0 to %6 for %6], %5[%c0 to %7 for %7]) : (!stream.resource<*>{%6}, !stream.resource<*>{%7}) -> !stream.resource<*>{%8}
  %10 = stream.tensor.sizeof tensor<12x6xf32> : index
  %11 = stream.async.transfer %9 : !stream.resource<*>{%10} -> !stream.resource<external>{%10}
  %12 = stream.tensor.export %11 : tensor<12x6xf32> in !stream.resource<external>{%10} -> !hal.buffer_view
  util.return %12 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof tensor<12x6xf32> : index
  %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
  %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %3 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
  %4 = stream.async.transfer %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %5 = stream.tensor.sizeof tensor<72xf32> : index
  %6 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2[%c0 to %5 for %5], %4[%c0 to %5 for %5]) : (!stream.resource<*>{%5}, !stream.resource<*>{%5}) -> !stream.resource<*>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
  %8 = stream.tensor.export %7 : tensor<12x6xf32> in !stream.resource<external>{%0} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof tensor<12x6xf32> : index
  %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
  %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %3 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
  %4 = stream.async.transfer %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %5 = stream.tensor.sizeof tensor<72xf32> : index
  %6 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2[%c0 to %5 for %5], %4[%c0 to %5 for %5]) : (!stream.resource<*>{%5}, !stream.resource<*>{%5}) -> !stream.resource<*>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
  %8 = stream.tensor.export %7 : tensor<12x6xf32> in !stream.resource<external>{%0} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof tensor<12x6xf32> : index
  %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
  %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %3 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
  %4 = stream.async.transfer %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %5 = stream.tensor.sizeof tensor<72xf32> : index
  %6 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2[%c0 to %5 for %5], %4[%c0 to %5 for %5]) : (!stream.resource<*>{%5}, !stream.resource<*>{%5}) -> !stream.resource<*>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
  %8 = stream.tensor.export %7 : tensor<12x6xf32> in !stream.resource<external>{%0} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.sizeof tensor<12x6xf32> : index
  %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
  %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %3 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
  %4 = stream.async.transfer %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
  %5 = stream.tensor.sizeof tensor<72xf32> : index
  %6 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2[%c0 to %5 for %5], %4[%c0 to %5 for %5]) : (!stream.resource<*>{%5}, !stream.resource<*>{%5}) -> !stream.resource<*>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
  %8 = stream.tensor.export %7 : tensor<12x6xf32> in !stream.resource<external>{%0} -> !hal.buffer_view
  util.return %8 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof tensor<12x6xf32> : index
    %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %3 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %5 = stream.tensor.sizeof tensor<72xf32> : index
    %6 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2[%c0 to %5 for %5], %4[%c0 to %5 for %5]) : (!stream.resource<*>{%5}, !stream.resource<*>{%5}) -> !stream.resource<*>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
    %8 = stream.tensor.export %7 : tensor<12x6xf32> in !stream.resource<external>{%0} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof tensor<12x6xf32> : index
    %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %3 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %5 = stream.tensor.sizeof tensor<72xf32> : index
    %6 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2[%c0 to %5 for %5], %4[%c0 to %5 for %5]) : (!stream.resource<*>{%5}, !stream.resource<*>{%5}) -> !stream.resource<*>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
    %8 = stream.tensor.export %7 : tensor<12x6xf32> in !stream.resource<external>{%0} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof tensor<12x6xf32> : index
    %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %3 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %5 = stream.tensor.sizeof tensor<72xf32> : index
    %6 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2[%c0 to %5 for %5], %4[%c0 to %5 for %5]) : (!stream.resource<*>{%5}, !stream.resource<*>{%5}) -> !stream.resource<*>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
    %8 = stream.tensor.export %7 : tensor<12x6xf32> in !stream.resource<external>{%0} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After CombineInitializers (iree-util-combine-initializers) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.sizeof tensor<12x6xf32> : index
    %1 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
    %2 = stream.async.transfer %1 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %3 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%0}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%0} -> !stream.resource<*>{%0}
    %5 = stream.tensor.sizeof tensor<72xf32> : index
    %6 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%2[%c0 to %5 for %5], %4[%c0 to %5 for %5]) : (!stream.resource<*>{%5}, !stream.resource<*>{%5}) -> !stream.resource<*>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<*>{%0} -> !stream.resource<external>{%0}
    %8 = stream.tensor.export %7 : tensor<12x6xf32> in !stream.resource<external>{%0} -> !hal.buffer_view
    util.return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After EncodeHostTensorsPass (iree-stream-encode-host-tensors) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %1 = stream.async.transfer %0 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%1[%c0 to %c288 for %c288], %3[%c0 to %c288 for %c288]) : (!stream.resource<*>{%c288}, !stream.resource<*>{%c288}) -> !stream.resource<*>{%c288}
  %5 = stream.async.transfer %4 : !stream.resource<*>{%c288} -> !stream.resource<external>{%c288}
  %6 = stream.tensor.export %5 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After EncodeDeviceTensorsPass (iree-stream-encode-device-tensors) //----- //
stream.executable private @add_dispatch_0 {
  stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    stream.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
      %c0 = arith.constant 0 : index
      %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
      %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
      %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
      %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
      %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
      %5 = tensor.empty() : tensor<72xf32>
      %6 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
      ^bb0(%in: f32, %in_0: f32, %out: f32):
        %7 = arith.addf %in, %in_0 : f32
        linalg.yield %7 : f32
      } -> tensor<72xf32>
      flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
      return
    }
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %1 = stream.async.transfer %0 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%1[%c0 to %c288 for %c288], %3[%c0 to %c288 for %c288]) : (!stream.resource<*>{%c288}, !stream.resource<*>{%c288}) -> !stream.resource<*>{%c288}
  %5 = stream.async.transfer %4 : !stream.resource<*>{%c288} -> !stream.resource<external>{%c288}
  %6 = stream.tensor.export %5 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %1 = stream.async.transfer %0 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%1[%c0 to %c288 for %c288], %3[%c0 to %c288 for %c288]) : (!stream.resource<*>{%c288}, !stream.resource<*>{%c288}) -> !stream.resource<*>{%c288}
  %5 = stream.async.transfer %4 : !stream.resource<*>{%c288} -> !stream.resource<external>{%c288}
  %6 = stream.tensor.export %5 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %1 = stream.async.transfer %0 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%1[%c0 to %c288 for %c288], %3[%c0 to %c288 for %c288]) : (!stream.resource<*>{%c288}, !stream.resource<*>{%c288}) -> !stream.resource<*>{%c288}
  %5 = stream.async.transfer %4 : !stream.resource<*>{%c288} -> !stream.resource<external>{%c288}
  %6 = stream.tensor.export %5 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %1 = stream.async.transfer %0 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%1[%c0 to %c288 for %c288], %3[%c0 to %c288 for %c288]) : (!stream.resource<*>{%c288}, !stream.resource<*>{%c288}) -> !stream.resource<*>{%c288}
  %5 = stream.async.transfer %4 : !stream.resource<*>{%c288} -> !stream.resource<external>{%c288}
  %6 = stream.tensor.export %5 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %1 = stream.async.transfer %0 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%1[%c0 to %c288 for %c288], %3[%c0 to %c288 for %c288]) : (!stream.resource<*>{%c288}, !stream.resource<*>{%c288}) -> !stream.resource<*>{%c288}
  %5 = stream.async.transfer %4 : !stream.resource<*>{%c288} -> !stream.resource<external>{%c288}
  %6 = stream.tensor.export %5 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %1 = stream.async.transfer %0 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
    %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%1[%c0 to %c288 for %c288], %3[%c0 to %c288 for %c288]) : (!stream.resource<*>{%c288}, !stream.resource<*>{%c288}) -> !stream.resource<*>{%c288}
    %5 = stream.async.transfer %4 : !stream.resource<*>{%c288} -> !stream.resource<external>{%c288}
    %6 = stream.tensor.export %5 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %1 = stream.async.transfer %0 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
    %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%1[%c0 to %c288 for %c288], %3[%c0 to %c288 for %c288]) : (!stream.resource<*>{%c288}, !stream.resource<*>{%c288}) -> !stream.resource<*>{%c288}
    %5 = stream.async.transfer %4 : !stream.resource<*>{%c288} -> !stream.resource<external>{%c288}
    %6 = stream.tensor.export %5 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %1 = stream.async.transfer %0 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
    %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%1[%c0 to %c288 for %c288], %3[%c0 to %c288 for %c288]) : (!stream.resource<*>{%c288}, !stream.resource<*>{%c288}) -> !stream.resource<*>{%c288}
    %5 = stream.async.transfer %4 : !stream.resource<*>{%c288} -> !stream.resource<external>{%c288}
    %6 = stream.tensor.export %5 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToAsyncResourcesPass (iree-stream-verify-lowering-to-async-resources) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %1 = stream.async.transfer %0 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
    %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%1[%c0 to %c288 for %c288], %3[%c0 to %c288 for %c288]) : (!stream.resource<*>{%c288}, !stream.resource<*>{%c288}) -> !stream.resource<*>{%c288}
    %5 = stream.async.transfer %4 : !stream.resource<*>{%c288} -> !stream.resource<external>{%c288}
    %6 = stream.tensor.export %5 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeCopyOnWritePass (iree-stream-materialize-copy-on-write) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %1 = stream.async.transfer %0 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%1[%c0 to %c288 for %c288], %3[%c0 to %c288 for %c288]) : (!stream.resource<*>{%c288}, !stream.resource<*>{%c288}) -> !stream.resource<*>{%c288}
  %5 = stream.async.transfer %4 : !stream.resource<*>{%c288} -> !stream.resource<external>{%c288}
  %6 = stream.tensor.export %5 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %1 = stream.async.transfer %0 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%1[%c0 to %c288 for %c288], %3[%c0 to %c288 for %c288]) : (!stream.resource<*>{%c288}, !stream.resource<*>{%c288}) -> !stream.resource<*>{%c288}
  %5 = stream.async.transfer %4 : !stream.resource<*>{%c288} -> !stream.resource<external>{%c288}
  %6 = stream.tensor.export %5 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After ElideAsyncCopiesPass (iree-stream-elide-async-copies) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %1 = stream.async.transfer %0 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
    %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%1[%c0 to %c288 for %c288], %3[%c0 to %c288 for %c288]) : (!stream.resource<*>{%c288}, !stream.resource<*>{%c288}) -> !stream.resource<*>{%c288}
    %5 = stream.async.transfer %4 : !stream.resource<*>{%c288} -> !stream.resource<external>{%c288}
    %6 = stream.tensor.export %5 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %1 = stream.async.transfer %0 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%1[%c0 to %c288 for %c288], %3[%c0 to %c288 for %c288]) : (!stream.resource<*>{%c288}, !stream.resource<*>{%c288}) -> !stream.resource<*>{%c288}
  %5 = stream.async.transfer %4 : !stream.resource<*>{%c288} -> !stream.resource<external>{%c288}
  %6 = stream.tensor.export %5 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After EmplaceAllocationsPass (iree-stream-emplace-allocations) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %1 = stream.async.transfer %0 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c288} -> !stream.resource<*>{%c288}
  %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%1[%c0 to %c288 for %c288], %3[%c0 to %c288 for %c288]) : (!stream.resource<*>{%c288}, !stream.resource<*>{%c288}) -> !stream.resource<*>{%c288}
  %5 = stream.async.transfer %4 : !stream.resource<*>{%c288} -> !stream.resource<external>{%c288}
  %6 = stream.tensor.export %5 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %6 : !hal.buffer_view
}

// -----// IR Dump After RefineUsagePass (iree-stream-refine-usage) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %2 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%0[%c0 to %c288 for %c288], %1[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
    %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %2 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%0[%c0 to %c288 for %c288], %1[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
  %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %2 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%0[%c0 to %c288 for %c288], %1[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
  %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %2 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%0[%c0 to %c288 for %c288], %1[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
  %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %2 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%0[%c0 to %c288 for %c288], %1[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
  %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %2 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%0[%c0 to %c288 for %c288], %1[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
  %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %2 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%0[%c0 to %c288 for %c288], %1[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
    %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %2 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%0[%c0 to %c288 for %c288], %1[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
    %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %2 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%0[%c0 to %c288 for %c288], %1[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
    %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyAsyncAccessRangesPass (iree-stream-verify-async-access-ranges) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %2 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%0[%c0 to %c288 for %c288], %1[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
    %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After ScheduleExecutionPass (iree-stream-schedule-execution) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %results, %result_timepoint = stream.async.execute with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288} {
    %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%arg2[%c0 to %c288 for %c288], %arg3[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
    stream.yield %4 : !stream.resource<external>{%c288}
  } => !stream.timepoint
  %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c288}
  %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After ScheduleConcurrencyPass (iree-stream-schedule-concurrency) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %results, %result_timepoint = stream.async.execute with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288} {
    %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%arg2[%c0 to %c288 for %c288], %arg3[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
    stream.yield %4 : !stream.resource<external>{%c288}
  } => !stream.timepoint
  %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c288}
  %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After PropagateTimepointsPass (iree-stream-propagate-timepoints) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %2 = stream.timepoint.immediate => !stream.timepoint
    %3 = stream.timepoint.immediate => !stream.timepoint
    %4 = stream.timepoint.join max(%2, %3) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%4) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288} {
      %7 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%arg2[%c0 to %c288 for %c288], %arg3[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
      stream.yield %7 : !stream.resource<external>{%c288}
    } => !stream.timepoint
    %5 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c288}
    %6 = stream.tensor.export %5 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeBuiltinsPass (iree-stream-materialize-builtins) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %2 = stream.timepoint.immediate => !stream.timepoint
    %3 = stream.timepoint.immediate => !stream.timepoint
    %4 = stream.timepoint.join max(%2, %3) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%4) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288} {
      %7 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%arg2[%c0 to %c288 for %c288], %arg3[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
      stream.yield %7 : !stream.resource<external>{%c288}
    } => !stream.timepoint
    %5 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c288}
    %6 = stream.tensor.export %5 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %results, %result_timepoint = stream.async.execute with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288} {
    %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%arg2[%c0 to %c288 for %c288], %arg3[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
    stream.yield %4 : !stream.resource<external>{%c288}
  } => !stream.timepoint
  %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c288}
  %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %results, %result_timepoint = stream.async.execute with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288} {
    %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%arg2[%c0 to %c288 for %c288], %arg3[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
    stream.yield %4 : !stream.resource<external>{%c288}
  } => !stream.timepoint
  %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c288}
  %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %results, %result_timepoint = stream.async.execute with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288} {
    %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%arg2[%c0 to %c288 for %c288], %arg3[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
    stream.yield %4 : !stream.resource<external>{%c288}
  } => !stream.timepoint
  %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c288}
  %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %results, %result_timepoint = stream.async.execute with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288} {
    %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%arg2[%c0 to %c288 for %c288], %arg3[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
    stream.yield %4 : !stream.resource<external>{%c288}
  } => !stream.timepoint
  %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c288}
  %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %results, %result_timepoint = stream.async.execute with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288} {
    %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%arg2[%c0 to %c288 for %c288], %arg3[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
    stream.yield %4 : !stream.resource<external>{%c288}
  } => !stream.timepoint
  %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c288}
  %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %3 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %results, %result_timepoint = stream.async.execute with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288} {
      %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%arg2[%c0 to %c288 for %c288], %arg3[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
      stream.yield %4 : !stream.resource<external>{%c288}
    } => !stream.timepoint
    %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c288}
    %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %results, %result_timepoint = stream.async.execute with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288} {
      %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%arg2[%c0 to %c288 for %c288], %arg3[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
      stream.yield %4 : !stream.resource<external>{%c288}
    } => !stream.timepoint
    %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c288}
    %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %results, %result_timepoint = stream.async.execute with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288} {
      %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%arg2[%c0 to %c288 for %c288], %arg3[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
      stream.yield %4 : !stream.resource<external>{%c288}
    } => !stream.timepoint
    %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c288}
    %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToAsyncPass (iree-stream-verify-lowering-to-async) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %results, %result_timepoint = stream.async.execute with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288} {
      %4 = stream.async.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%arg2[%c0 to %c288 for %c288], %arg3[%c0 to %c288 for %c288]) : (!stream.resource<external>{%c288}, !stream.resource<external>{%c288}) -> !stream.resource<external>{%c288}
      stream.yield %4 : !stream.resource<external>{%c288}
    } => !stream.timepoint
    %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c288}
    %3 = stream.tensor.export %2 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After ScheduleAllocationPass (iree-stream-schedule-allocation) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %c0_0 = arith.constant 0 : index
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0_0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After PackConstantsPass (iree-stream-pack-constants) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %c0_0 = arith.constant 0 : index
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0_0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After LayoutSlicesPass (iree-stream-layout-slices) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %c0_0 = arith.constant 0 : index
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0_0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After PropagateSubranges (iree-util-propagate-subranges) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %c0_0 = arith.constant 0 : index
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0_0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToCmdPass (iree-stream-verify-lowering-to-cmd) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#map = affine_map<(d0) -> (d0)>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ElideTimepointsPass (iree-stream-elide-timepoints) //----- //
#map = affine_map<(d0) -> (d0)>
module attributes {iree.fixedpoint.iteration = 0 : index} {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseDispatchBindingsPass (iree-stream-fuse-dispatch-bindings) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%arg3] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%arg4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%arg5] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%c0, %c0, %c0 : index, index, index) {
        ro %arg2[%c0_0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0_0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0_0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateDispatchArgumentsPass (iree-stream-annotate-dispatch-arguments) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: index {stream.values = [0 : index]}, %arg4: index {stream.values = [0 : index]}, %arg5: index {stream.values = [0 : index]}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%arg3] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%arg4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%arg5] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%c0, %c0, %c0 : index, index, index) {
        ro %arg2[%c0_0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0_0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0_0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateDispatchAssumptionsPass (iree-stream-annotate-dispatch-assumptions) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: index {stream.values = [0 : index]}, %arg4: index {stream.values = [0 : index]}, %arg5: index {stream.values = [0 : index]}) {
        %0:3 = util.assume.int 
            %arg3<umin = 0, umax = 0>, 
            %arg4<umin = 0, umax = 0>, 
            %arg5<umin = 0, umax = 0>
          : index, index, index
        %c0 = arith.constant 0 : index
        %1 = stream.binding.subspan %arg0[%0#0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg1[%0#1] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %3 = stream.binding.subspan %arg2[%0#2] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = flow.dispatch.tensor.load %2, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %6 = tensor.empty() : tensor<72xf32>
        %7 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%4, %5 : tensor<72xf32>, tensor<72xf32>) outs(%6 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %8 = arith.addf %in, %in_0 : f32
          linalg.yield %8 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%c0, %c0, %c0 : index, index, index) {
        ro %arg2[%c0_0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0_0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0_0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After PackDispatchOperandsPass (iree-stream-pack-dispatch-operands) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %c32_i64_0 = arith.constant 32 : i64
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64_0 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %c32_i64_1 = arith.constant 32 : i64
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64_1 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %15:3 = util.assume.int 
            %4<umin = 0, umax = 0>, 
            %9<umin = 0, umax = 0>, 
            %14<umin = 0, umax = 0>
          : index, index, index
        %c0 = arith.constant 0 : index
        %16 = stream.binding.subspan %arg0[%15#0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %17 = stream.binding.subspan %arg1[%15#1] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %18 = stream.binding.subspan %arg2[%15#2] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %19 = flow.dispatch.tensor.load %16, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %21 = tensor.empty() : tensor<72xf32>
        %22 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%19, %20 : tensor<72xf32>, tensor<72xf32>) outs(%21 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_2: f32, %out: f32):
          %23 = arith.addf %in, %in_2 : f32
          linalg.yield %23 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %22, %18, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %c0_i64 = arith.constant 0 : i64
    %c0_i32 = arith.constant 0 : i32
    %c32_i64 = arith.constant 32 : i64
    %c0_i64_1 = arith.constant 0 : i64
    %c0_i32_2 = arith.constant 0 : i32
    %c0_i64_3 = arith.constant 0 : i64
    %c0_i32_4 = arith.constant 0 : i32
    %c32_i64_5 = arith.constant 32 : i64
    %c0_i64_6 = arith.constant 0 : i64
    %c0_i32_7 = arith.constant 0 : i32
    %c0_i64_8 = arith.constant 0 : i64
    %c0_i32_9 = arith.constant 0 : i32
    %c32_i64_10 = arith.constant 32 : i64
    %c0_i64_11 = arith.constant 0 : i64
    %c0_i32_12 = arith.constant 0 : i32
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%c0_i32, %c0_i32_2, %c0_i32_4, %c0_i32_7, %c0_i32_9, %c0_i32_12 : i32, i32, i32, i32, i32, i32) {
        ro %arg2[%c0_0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0_0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0_0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c0_i32 = arith.constant 0 : i32
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c0_i32 = arith.constant 0 : i32
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c0_i32 = arith.constant 0 : i32
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c0_i32 = arith.constant 0 : i32
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c0_i32 = arith.constant 0 : i32
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %15:3 = util.assume.int 
            %4<umin = 0, umax = 0>, 
            %9<umin = 0, umax = 0>, 
            %14<umin = 0, umax = 0>
          : index, index, index
        %16 = stream.binding.subspan %arg0[%15#0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %17 = stream.binding.subspan %arg1[%15#1] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %18 = stream.binding.subspan %arg2[%15#2] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %19 = flow.dispatch.tensor.load %16, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %21 = tensor.empty() : tensor<72xf32>
        %22 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%19, %20 : tensor<72xf32>, tensor<72xf32>) outs(%21 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %23 = arith.addf %in, %in_0 : f32
          linalg.yield %23 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %22, %18, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c0_i32 = arith.constant 0 : i32
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %15:3 = util.assume.int 
            %4<umin = 0, umax = 0>, 
            %9<umin = 0, umax = 0>, 
            %14<umin = 0, umax = 0>
          : index, index, index
        %16 = stream.binding.subspan %arg0[%15#0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %17 = stream.binding.subspan %arg1[%15#1] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %18 = stream.binding.subspan %arg2[%15#2] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %19 = flow.dispatch.tensor.load %16, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %21 = tensor.empty() : tensor<72xf32>
        %22 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%19, %20 : tensor<72xf32>, tensor<72xf32>) outs(%21 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %23 = arith.addf %in, %in_0 : f32
          linalg.yield %23 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %22, %18, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c0_i32 = arith.constant 0 : i32
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %15:3 = util.assume.int 
            %4<umin = 0, umax = 0>, 
            %9<umin = 0, umax = 0>, 
            %14<umin = 0, umax = 0>
          : index, index, index
        %16 = stream.binding.subspan %arg0[%15#0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %17 = stream.binding.subspan %arg1[%15#1] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %18 = stream.binding.subspan %arg2[%15#2] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %19 = flow.dispatch.tensor.load %16, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %21 = tensor.empty() : tensor<72xf32>
        %22 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%19, %20 : tensor<72xf32>, tensor<72xf32>) outs(%21 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %23 = arith.addf %in, %in_0 : f32
          linalg.yield %23 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %22, %18, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c0_i32 = arith.constant 0 : i32
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32) {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldUniformOperandsPass (iree-stream-fold-uniform-operands) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0_i32 = arith.constant 0 : i32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %c0_i32 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %c0_i32 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %c0_i32 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %c0_i32 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %c0_i32 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %c0_i32 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %15:3 = util.assume.int 
            %4<umin = 0, umax = 0>, 
            %9<umin = 0, umax = 0>, 
            %14<umin = 0, umax = 0>
          : index, index, index
        %16 = stream.binding.subspan %arg0[%15#0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %17 = stream.binding.subspan %arg1[%15#1] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %18 = stream.binding.subspan %arg2[%15#2] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %19 = flow.dispatch.tensor.load %16, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %20 = flow.dispatch.tensor.load %17, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %21 = tensor.empty() : tensor<72xf32>
        %22 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%19, %20 : tensor<72xf32>, tensor<72xf32>) outs(%21 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %23 = arith.addf %in, %in_0 : f32
          linalg.yield %23 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %22, %18, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c0_i32 = arith.constant 0 : i32
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After OptimizeIntArithmetic (iree-util-optimize-int-arithmetic) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeTargetDevicesPass (iree-hal-materialize-target-devices) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveDevicePromisesPass (iree-hal-resolve-device-promises) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ResolveDeviceAliasesPass (iree-hal-resolve-device-aliases) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyDevicesPass (iree-hal-verify-devices) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
  %c288 = arith.constant 288 : index
  %c0 = arith.constant 0 : index
  %c6 = arith.constant 6 : index
  %c12 = arith.constant 12 : index
  %element_type_f32 = hal.element_type<f32> : i32
  %dense_row_major = hal.encoding_type<dense_row_major> : i32
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
  %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
  %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
    stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
      ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
      ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
      wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
  %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
  util.return %4 : !hal.buffer_view
}

// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyDevicesPass (iree-hal-verify-devices) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


tosa.mlir:0:0: error: no HAL devices defined in the module; use the module-level hal.device.targets attribute, the --iree-hal-target-device= flag, or provide inputs with global !hal.devices defined
// -----// IR Dump After MaterializeInterfacesPass Failed (iree-hal-materialize-interfaces) //----- //
#map = affine_map<(d0) -> (d0)>
module {
  stream.executable private @add_dispatch_0 {
    stream.executable.export public @add_dispatch_0_elementwise_72_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @add_dispatch_0_elementwise_72_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<72xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        %3 = flow.dispatch.tensor.load %0, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %4 = flow.dispatch.tensor.load %1, offsets = [0], sizes = [72], strides = [1] : !flow.dispatch.tensor<readonly:tensor<72xf32>> -> tensor<72xf32>
        %5 = tensor.empty() : tensor<72xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%3, %4 : tensor<72xf32>, tensor<72xf32>) outs(%5 : tensor<72xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<72xf32>
        flow.dispatch.tensor.store %6, %2, offsets = [0], sizes = [72], strides = [1] : tensor<72xf32> -> !flow.dispatch.tensor<writeonly:tensor<72xf32>>
        return
      }
    }
  }
  util.func public @add(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = "sync func @add(%input0: tensor<12x6xf32>, %input1: tensor<12x6xf32>) -> (%output0: tensor<12x6xf32>)"}} {
    %c288 = arith.constant 288 : index
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c12 = arith.constant 12 : index
    %element_type_f32 = hal.element_type<f32> : i32
    %dense_row_major = hal.encoding_type<dense_row_major> : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input0") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input1") shape([%c12, %c6]) type(%element_type_f32) encoding(%dense_row_major)
    %1 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<12x6xf32> in !stream.resource<external>{%c288}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%c288} => !stream.timepoint
    %2 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg2: !stream.resource<external>{%c288}, %1 as %arg3: !stream.resource<external>{%c288}, %result as %arg4: !stream.resource<external>{%c288}) {
      stream.cmd.dispatch @add_dispatch_0::@add_dispatch_0_elementwise_72_f32 {
        ro %arg2[%c0 for %c288] : !stream.resource<external>{%c288},
        ro %arg3[%c0 for %c288] : !stream.resource<external>{%c288},
        wo %arg4[%c0 for %c288] : !stream.resource<external>{%c288}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c288}
    %4 = stream.tensor.export %3 : tensor<12x6xf32> in !stream.resource<external>{%c288} -> !hal.buffer_view
    util.return %4 : !hal.buffer_view
  }
}


